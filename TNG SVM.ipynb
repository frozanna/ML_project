{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, average_precision_score\n",
    "from random import sample, randint, randrange\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start_time = default_timer()\n",
    "\n",
    "    class _Timer():\n",
    "      start = start_time\n",
    "      end = default_timer()\n",
    "      duration = end - start\n",
    "\n",
    "    yield _Timer\n",
    "\n",
    "    end_time = default_timer()\n",
    "    _Timer.end = end_time\n",
    "    _Timer.duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "y_train = newsgroups_train.target\n",
    "x_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_test = newsgroups_test.target\n",
    "classes_count = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change dimensions to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500)\n",
    "svd.fit(x_train)\n",
    "svd_x_train = svd.transform(x_train)\n",
    "svd_x_test = svd.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_res, y_train_res = resample(svd_x_train, y_train, n_samples=5000, replace=False, random_state=0)\n",
    "#x_test_res, y_test_res = resample(svd_x_test, y_test, n_samples=500, replace=False, random_state=0)\n",
    "#x_train_res = x_train_res.reshape((x_train_res.shape[0],-1))\n",
    "#x_test_res = x_test_res.reshape((x_test_res.shape[0],-1))\n",
    "#y_train_res = y_train_res.reshape((y_train_res.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler(with_mean=False).fit(x_train)\n",
    "#x_train_scaled = scaler.transform(x_train) # scaling data\n",
    "#x_test_scaled = scaler.transform(x_test)\n",
    "#print(x_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM on full data and full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(probability=True)\n",
    "clf.fit(svd_x_train, y_train)\n",
    "#clf.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(svd_x_test)\n",
    "#y_pred = clf.predict(x_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy = accuracy_score(y_test_res, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887679235262879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy #0.78956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904610758374129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score = f1_score(y_test, y_pred, average='weighted')\n",
    "#f_score = f1_score(y_test_res, y_pred, average='weighted')\n",
    "f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 sub-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svd_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8e62db3fcc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msamples_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msamples_all_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_x_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfeatures_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svd_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_samples = [0.1, 0.25]\n",
    "n_features = [0.25, 0.5, 0.75]\n",
    "\n",
    "samples_all = svd_x_train.shape[0]\n",
    "samples_all_test = svd_x_test.shape[0]\n",
    "features_all = svd_x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinorClassifiers:\n",
    "    def __init__(self, n_samples, n_features):\n",
    "        self.n_samples = n_samples\n",
    "        self.n_features = n_features\n",
    "        self.classifiers = []\n",
    "        self.predictions = []\n",
    "        self.cut_features = []\n",
    "    \n",
    "    def get_params(self, deep = False):\n",
    "        return {\n",
    "            'n_samples': self.n_samples,\n",
    "            'n_features': self.n_features,   \n",
    "        }\n",
    "    \n",
    "    def predict(self, X):\n",
    "        for i in range(len(self.classifiers)):\n",
    "            classifier = self.classifiers[i]\n",
    "            x_test = X[:,self.cut_features[i]]\n",
    "            y_pred = classifier.predict(x_test)\n",
    "            pred = classifier.predict_proba(x_test)\n",
    "            self.predictions.append((y_pred, pred))\n",
    "            \n",
    "        return majority_pred(self.predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        m = X.shape[0]\n",
    "        results = [[0 for x in range(classes_count)] for y in range(m)]\n",
    "        for i in range(len(self.classifiers)):\n",
    "            classifier = self.classifiers[i]\n",
    "            x_test = X[:,self.cut_features[i]]\n",
    "            y_pred = classifier.predict(x_test)\n",
    "            pred = classifier.predict_proba(x_test)\n",
    "            self.predictions.append((y_pred, pred))\n",
    "            \n",
    "        for (_, pred_proba) in self.predictions:\n",
    "            for i in range(m):\n",
    "                for j in range(classes_count):\n",
    "                    results[i][j] += pred_proba[i][j]\n",
    "                \n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                results[i][j] /= classes_count            \n",
    "        return results\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        feature_list = [n for n in range(500)]\n",
    "        samples_all = X.shape[0]\n",
    "        features_all = X.shape[1]\n",
    "\n",
    "        for samples in self.n_samples:\n",
    "            for features in self.n_features:\n",
    "                f = sample(feature_list, int(features_all * features))\n",
    "                self.cut_features.append(f)\n",
    "                x_train_f = X[:,f]\n",
    "                \n",
    "                x_train_s, y_train_s = resample(x_train_f, Y, n_samples=int(samples * samples_all), replace=False, random_state=0)\n",
    "\n",
    "                svm_clf = SVC(probability=True)\n",
    "                svm_clf.fit(x_train_s, y_train_s)\n",
    "                \n",
    "                self.classifiers.append(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minor_classifiers(samples_perc, features_perc):\n",
    "    feature_list = [n for n in range(500)]\n",
    "    classifiers = []\n",
    "    \n",
    "    for samples in samples_perc:\n",
    "        for features in features_perc:\n",
    "            f = sample(feature_list, int(features_all * features))\n",
    "            x_train_f = svd_x_train[:,f]\n",
    "            x_test_f = svd_x_test[:,f]\n",
    "            \n",
    "            x_train_s, y_train_s = resample(x_train_f, y_train, n_samples=int(samples * samples_all), replace=False, random_state=0)\n",
    "            #x_test_s, y_test_s = resample(svd_x_test, y_test, n_samples=int(samples * samples_all_test), replace=False, random_state=0)\n",
    "            \n",
    "            svm_clf = SVC(probability=True)\n",
    "            svm_clf.fit(x_train_s, y_train_s)\n",
    "            \n",
    "            y_pred = svm_clf.predict(x_test_f)\n",
    "            pred = svm_clf.predict_proba(x_test_f)\n",
    "            \n",
    "            classifiers.append((y_pred, pred))\n",
    "            \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = get_minor_classifiers(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pred(predictions):\n",
    "    #predictions = list of tuples \n",
    "    m = len(predictions[0][0])\n",
    "    all_results = [[0 for x in range(classes_count)] for y in range(m)] \n",
    "    results = [0] * m\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                all_results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        results[i] = all_results[i].index(max(all_results[i]))\n",
    "    return results\n",
    "\n",
    "def majority_pred(predictions):\n",
    "    m = len(predictions[0][0])\n",
    "    results = [0] * m\n",
    "    for i in range(m):\n",
    "        all_results = [0 for x in range(classes_count)] \n",
    "        for (pred, _) in predictions:\n",
    "            all_results[pred[i]] += 1\n",
    "        results[i] = all_results.index(max(all_results))        \n",
    "    return results\n",
    "\n",
    "def borda_pred(predictions):\n",
    "    m = len(predictions[0][0])\n",
    "    all_results = [[0 for x in range(classes_count)] for y in range(m)] \n",
    "    results = [0] * m\n",
    "    \n",
    "    def get_final_borda_points(predictions):\n",
    "        return np.argsort(np.argsort(predictions)).tolist()\n",
    "\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            pred_proba[i] = get_final_borda_points(pred_proba[i])\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                all_results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        results[i] = all_results[i].index(max(all_results[i]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'majority_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e766205c85cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmajority_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'majority_pred' is not defined"
     ]
    }
   ],
   "source": [
    "res = majority_pred(clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686404673393521"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_label(labels, percent):\n",
    "    labels_with_noise = deepcopy(labels)\n",
    "    arr_size = labels.shape[0]\n",
    "    indexes = [n for n in range(arr_size)]\n",
    "    indexes_to_change = sample(indexes, int(arr_size * percent))\n",
    "    \n",
    "    for i in indexes_to_change:\n",
    "        old_val = labels[i]\n",
    "        new_val = randint(0, classes_count)\n",
    "        while old_val == new_val:\n",
    "            new_val = randint(0, classes_count)\n",
    "        labels_with_noise[i] = new_val\n",
    "        \n",
    "    return labels_with_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_data(data, percent):\n",
    "    m = data.shape[0]\n",
    "    n = data.shape[1]\n",
    "    new_data = deepcopy(data)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            rand = randrange(-1, 2, 2) #random integer from {-1, 1}\n",
    "            new_data[i][j] = (1 + rand * percent) * data[i][j]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 111.54180649999944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_100iter = SVC(probability=True, max_iter=50) #221 dla 100, 24 dla 10, 46 dla 20, 112 dla 50\n",
    "\n",
    "with elapsed_timer() as t:\n",
    "    clf_100iter.fit(svd_x_train, y_train)\n",
    "\n",
    "print(\"duration: \" + str(t.duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki jakości klasyfikatorów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MinorClassifiers(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(svd_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(svd_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(clf, svd_x_train, y_train, cv=5, scoring=('accuracy', 'neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75828546 0.75828546 0.76535572 0.76844896 0.74093722]\n",
      "[-1.00897419 -1.04675676 -1.00527875 -1.05143864 -1.09940959]\n"
     ]
    }
   ],
   "source": [
    "print(scores['test_accuracy'])\n",
    "print(scores['test_neg_log_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87538665, 0.87627044, 0.88201502, 0.87892179, 0.877542  ])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UWAGA NIE PUSZCZAĆ BEZ POWODU - linijka niezakomentowana żeby uniknąć restartowania kernela\n",
    "#cross-validation -> wybór metody fuzji decyzji?\n",
    "scores = cross_validate(clf, svd_x_train, y_train, cv=5, scoring=('accuracy', 'neg_log_loss')) #zrobić klasę Model, robiącą model z 10 klasyfikatorów\n",
    "print(scores['test_accuracy'])\n",
    "print(scores['test_neg_log_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.79\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(svd_x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score: {0:0.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss score: 0.72\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(svd_x_test)\n",
    "loss = log_loss(y_test, y_pred_proba)\n",
    "print('Loss score: {0:0.2f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-8aaf108fd516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maverage_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision-recall score: {0:0.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_precision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[1;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[0;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[1;32m--> 215\u001b[1;33m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "average_precision = average_precision_score(y_test, y_pred, pos_label=1)\n",
    "print('Precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[2.0,3.0], [2.0,4.], [4.,5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22475435 -0.06248808 -0.01441603 ... -0.0168442   0.02101432\n",
      "  -0.0191214 ]\n",
      " [ 0.12599262 -0.08438557 -0.0357827  ... -0.01513339  0.00517915\n",
      "   0.02194321]\n",
      " [ 0.3346583  -0.04556982 -0.07380376 ...  0.00602186  0.01392154\n",
      "  -0.02985655]\n",
      " ...\n",
      " [ 0.1662913  -0.00550221 -0.0884303  ...  0.01776318 -0.00348805\n",
      "   0.01692393]\n",
      " [ 0.20675388 -0.07267247  0.03741476 ...  0.03050179  0.02278233\n",
      "  -0.02552414]\n",
      " [ 0.09054867 -0.09988643  0.00410151 ...  0.00048173 -0.02367268\n",
      "   0.00355212]]\n"
     ]
    }
   ],
   "source": [
    "c = make_noise_data(svd_x_train, 0.1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, average_precision_score\n",
    "from random import sample, randint, randrange\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start_time = default_timer()\n",
    "\n",
    "    class _Timer():\n",
    "      start = start_time\n",
    "      end = default_timer()\n",
    "      duration = end - start\n",
    "\n",
    "    yield _Timer\n",
    "\n",
    "    end_time = default_timer()\n",
    "    _Timer.end = end_time\n",
    "    _Timer.duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "y_train = newsgroups_train.target\n",
    "x_test = vectorizer.transform(newsgroups_test.data)\n",
    "y_test = newsgroups_test.target\n",
    "#x_train = np.concatenate((x_train, x_test))\n",
    "#y_train = np.concatenate((y_train, y_test))\n",
    "classes_count = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change dimensions to 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500)\n",
    "svd.fit(x_train)\n",
    "svd_x_train = svd.transform(x_train)\n",
    "svd_x_test = svd.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_x_train = np.concatenate((svd_x_train, svd_x_test))\n",
    "y_train = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_res, y_train_res = resample(svd_x_train, y_train, n_samples=5000, replace=False, random_state=0)\n",
    "#x_test_res, y_test_res = resample(svd_x_test, y_test, n_samples=500, replace=False, random_state=0)\n",
    "#x_train_res = x_train_res.reshape((x_train_res.shape[0],-1))\n",
    "#x_test_res = x_test_res.reshape((x_test_res.shape[0],-1))\n",
    "#y_train_res = y_train_res.reshape((y_train_res.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler(with_mean=False).fit(x_train)\n",
    "#x_train_scaled = scaler.transform(x_train) # scaling data\n",
    "#x_test_scaled = scaler.transform(x_test)\n",
    "#print(x_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM on full data and full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True, max_iter=200)\n",
    "#clf.fit(svd_x_train, y_train)\n",
    "#clf.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = svd_x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = int(m*0.1)\n",
    "svd_x_train_10 = svd_x_train[:m3]\n",
    "y_train_10 = y_train[:m3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_noise_40 = make_noise_label(y_train, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846,)\n",
      "(18846, 500)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_noise_40.shape)\n",
    "print(svd_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(clf, svd_x_train, y_train, cv=5, scoring=('accuracy', \n",
    "                                                    'neg_log_loss', \n",
    "                                                    'neg_mean_squared_error', \n",
    "                                                    'roc_auc_ovr', \n",
    "                                                    'f1_weighted', \n",
    "                                                    'precision_weighted', \n",
    "                                                    'recall_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([453.452003  , 452.28610563, 452.48716164, 447.85763693,\n",
       "        450.32840657]),\n",
       " 'score_time': array([46.16600728, 46.40932512, 46.56393313, 45.55130672, 45.94004512]),\n",
       " 'test_accuracy': array([0.86949602, 0.88007429, 0.88166622, 0.83443884, 0.83762271]),\n",
       " 'test_neg_log_loss': array([-0.47028495, -0.45748055, -0.45810768, -0.56722823, -0.54911391]),\n",
       " 'test_neg_mean_squared_error': array([-6.30371353, -5.90501459, -5.07084107, -9.62111966, -9.44229239]),\n",
       " 'test_roc_auc_ovr': array([0.99272923, 0.99265828, 0.99277632, 0.98831115, 0.98951535]),\n",
       " 'test_f1_weighted': array([0.87051746, 0.88002696, 0.88256631, 0.83389696, 0.83774838]),\n",
       " 'test_precision_weighted': array([0.8735847 , 0.88092778, 0.8848363 , 0.83623437, 0.84251736]),\n",
       " 'test_recall_weighted': array([0.86949602, 0.88007429, 0.88166622, 0.83443884, 0.83762271])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(clf, svd_x_train, y_train_noise_40, cv=5, scoring=('accuracy', \n",
    "                                                    'neg_log_loss', \n",
    "                                                    'neg_mean_squared_error', \n",
    "                                                    'roc_auc_ovr', \n",
    "                                                    'f1_weighted', \n",
    "                                                    'precision_weighted', \n",
    "                                                    'recall_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1244.50412655, 1570.05026317, 1476.82827353, 1522.17273259,\n",
       "        1421.41617584]),\n",
       " 'score_time': array([72.63192344, 82.25924134, 82.61139894, 88.18289876, 73.61998105]),\n",
       " 'test_accuracy': array([0.5       , 0.50464314, 0.4887238 , 0.49376492, 0.47545768]),\n",
       " 'test_neg_log_loss': array([-2.27421874, -2.24522513, -2.30234006, -2.23431492, -2.29031023]),\n",
       " 'test_neg_mean_squared_error': array([-34.75251989, -34.11488458, -34.23985142, -35.36004245,\n",
       "        -34.06924914]),\n",
       " 'test_roc_auc_ovr': array([0.77234373, 0.77954066, 0.75769786, 0.7747673 , 0.76451044]),\n",
       " 'test_f1_weighted': array([0.49584589, 0.49774046, 0.48334969, 0.48867876, 0.46880907]),\n",
       " 'test_precision_weighted': array([0.49512082, 0.49420359, 0.48109027, 0.48748494, 0.46745597]),\n",
       " 'test_recall_weighted': array([0.5       , 0.50464314, 0.4887238 , 0.49376492, 0.47545768])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(svd_x_test)\n",
    "#y_pred = clf.predict(x_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#accuracy = accuracy_score(y_test_res, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873074880509825"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy #0.78956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888587724079459"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score = f1_score(y_test, y_pred, average='weighted')\n",
    "#f_score = f1_score(y_test_res, y_pred, average='weighted')\n",
    "f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 sub-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [0.1, 0.25, 0.35, 0.5]\n",
    "n_features = [0.25, 0.5, 0.75]\n",
    "n_classifiers = 12\n",
    "\n",
    "samples_all = svd_x_train.shape[0]\n",
    "samples_all_test = svd_x_test.shape[0]\n",
    "features_all = svd_x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinorClassifiers:\n",
    "    def __init__(self, n_samples, n_features):\n",
    "        self.n_samples = n_samples\n",
    "        self.n_features = n_features\n",
    "        self.classifiers = []\n",
    "        self.predictions = []\n",
    "        self.cut_features = []\n",
    "    \n",
    "    def get_params(self, deep = False):\n",
    "        return {\n",
    "            'n_samples': self.n_samples,\n",
    "            'n_features': self.n_features,   \n",
    "        }\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.predictions == []:\n",
    "            for i in range(len(self.classifiers)):\n",
    "                classifier = self.classifiers[i]\n",
    "                x_test = X[:,self.cut_features[i]]\n",
    "                y_pred = classifier.predict(x_test)\n",
    "                pred = classifier.predict_proba(x_test)\n",
    "                self.predictions.append((y_pred, pred))\n",
    "            \n",
    "        return average_pred(self.predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.predictions == []:\n",
    "            for i in range(len(self.classifiers)):\n",
    "                classifier = self.classifiers[i]\n",
    "                x_test = X[:,self.cut_features[i]]\n",
    "                y_pred = classifier.predict(x_test)\n",
    "                pred = classifier.predict_proba(x_test)\n",
    "                self.predictions.append((y_pred, pred))\n",
    "        return average_pred_proba(self.predictions, len(self.classifiers))\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        feature_list = [n for n in range(500)]\n",
    "        samples_all = X.shape[0]\n",
    "        features_all = X.shape[1]\n",
    "\n",
    "        for samples in self.n_samples:\n",
    "            for features in self.n_features:\n",
    "                f = sample(feature_list, int(features_all * features))\n",
    "                self.cut_features.append(f)\n",
    "                x_train_f = X[:,f]\n",
    "                \n",
    "                x_train_s, y_train_s = resample(x_train_f, Y, n_samples=int(samples * samples_all), replace=False, random_state=0)\n",
    "\n",
    "                svm_clf = SVC(probability=True, max_iter=max_iters)\n",
    "                svm_clf.fit(x_train_s, y_train_s)\n",
    "                \n",
    "                self.classifiers.append(svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minor_classifiers(samples_perc, features_perc):\n",
    "    feature_list = [n for n in range(500)]\n",
    "    classifiers = []\n",
    "    \n",
    "    for samples in samples_perc:\n",
    "        for features in features_perc:\n",
    "            f = sample(feature_list, int(features_all * features))\n",
    "            x_train_f = svd_x_train[:,f]\n",
    "            x_test_f = svd_x_test[:,f]\n",
    "            \n",
    "            x_train_s, y_train_s = resample(x_train_f, y_train, n_samples=int(samples * samples_all), replace=False, random_state=0)\n",
    "            #x_test_s, y_test_s = resample(svd_x_test, y_test, n_samples=int(samples * samples_all_test), replace=False, random_state=0)\n",
    "            \n",
    "            svm_clf = SVC(probability=True)\n",
    "            svm_clf.fit(x_train_s, y_train_s)\n",
    "            \n",
    "            y_pred = svm_clf.predict(x_test_f)\n",
    "            pred = svm_clf.predict_proba(x_test_f)\n",
    "            \n",
    "            classifiers.append((y_pred, pred))\n",
    "            \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clas = get_minor_classifiers(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pred(predictions):\n",
    "    #predictions = list of tuples \n",
    "    m = len(predictions[0][0])\n",
    "    all_results = [[0 for x in range(classes_count)] for y in range(m)] \n",
    "    results = [0] * m\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                all_results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        results[i] = all_results[i].index(max(all_results[i]))\n",
    "    return results\n",
    "\n",
    "def average_pred_proba(predictions, n_classifiers):\n",
    "    m = len(predictions[0][0])\n",
    "    results = [[0 for x in range(classes_count)] for y in range(m)]\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        for j in range(classes_count):\n",
    "            results[i][j] /= n_classifiers            \n",
    "    return results\n",
    "\n",
    "def majority_pred(predictions):\n",
    "    m = len(predictions[0][0])\n",
    "    results = [0] * m\n",
    "    for i in range(m):\n",
    "        all_results = [0 for x in range(classes_count)] \n",
    "        for (pred, _) in predictions:\n",
    "            all_results[pred[i]] += 1\n",
    "        results[i] = all_results.index(max(all_results))        \n",
    "    return results\n",
    "\n",
    "def majority_pred_proba(predictions, n_classifiers):\n",
    "    m = len(predictions[0][0])\n",
    "    results = [[0 for x in range(classes_count)] for y in range(m)]\n",
    "    classifiers_votes_count = [0] * m\n",
    "    majority_results = majority_pred(predictions)\n",
    "    for classifier in range(0, n_classifiers):\n",
    "        for i in range(m):\n",
    "            voted_class = majority_results[i] \n",
    "            (pred, pred_proba) = predictions[classifier]\n",
    "            if(pred[i] == voted_class):\n",
    "                classifiers_votes_count[i] += 1\n",
    "                for j in range(classes_count):\n",
    "                    results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        for j in range(classes_count):\n",
    "            results[i][j] /= classifiers_votes_count[i]\n",
    "    return results      \n",
    "    \n",
    "\n",
    "def borda_pred(predictions):\n",
    "    m = len(predictions[0][0])\n",
    "    all_results = [[0 for x in range(classes_count)] for y in range(m)] \n",
    "    results = [0] * m\n",
    "    \n",
    "    def get_final_borda_points(predictions):\n",
    "        return np.argsort(np.argsort(predictions)).tolist()\n",
    "\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            pred_proba[i] = get_final_borda_points(pred_proba[i])\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                all_results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        results[i] = all_results[i].index(max(all_results[i]))\n",
    "    return results\n",
    "\n",
    "def borda_pred_proba(predictions, n_classifiers):\n",
    "    m = len(predictions[0][0])\n",
    "    results = [[0 for x in range(classes_count)] for y in range(m)] \n",
    "    \n",
    "    def get_final_borda_points(predictions):\n",
    "        return np.argsort(np.argsort(predictions)).tolist()\n",
    "\n",
    "    def get_points():\n",
    "        sum = 0\n",
    "        for i in range(classes_count):\n",
    "            sum += i\n",
    "        return sum * n_classifiers\n",
    "    \n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            pred_proba[i] = get_final_borda_points(pred_proba[i])\n",
    "    for (_, pred_proba) in predictions:\n",
    "        for i in range(m):\n",
    "            for j in range(classes_count):\n",
    "                results[i][j] += pred_proba[i][j]\n",
    "    for i in range(m):\n",
    "        for j in range(classes_count):\n",
    "            results[i][j] /= get_points()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e766205c85cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmajority_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clas' is not defined"
     ]
    }
   ],
   "source": [
    "res = majority_pred(clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fd54f820c74d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873074880509825"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_label(labels, percent):\n",
    "    labels_with_noise = deepcopy(labels)\n",
    "    arr_size = labels.shape[0]\n",
    "    indexes = [n for n in range(arr_size)]\n",
    "    indexes_to_change = sample(indexes, int(arr_size * percent))\n",
    "    \n",
    "    for i in indexes_to_change:\n",
    "        old_val = labels[i]\n",
    "        new_val = randint(0, classes_count-1)\n",
    "        while old_val == new_val:\n",
    "            new_val = randint(0, classes_count-1)\n",
    "        labels_with_noise[i] = new_val\n",
    "        \n",
    "    return labels_with_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_data(data, percent):\n",
    "    m = data.shape[0]\n",
    "    n = data.shape[1]\n",
    "    new_data = deepcopy(data)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            rand = randrange(-1, 2, 2) #random integer from {-1, 1}\n",
    "            new_data[i][j] = (1 + rand * percent) * data[i][j]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 111.54180649999944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_100iter = SVC(probability=True, max_iter=50) #221 dla 100, 24 dla 10, 46 dla 20, 112 dla 50\n",
    "\n",
    "with elapsed_timer() as t:\n",
    "    clf_100iter.fit(svd_x_train, y_train)\n",
    "\n",
    "print(\"duration: \" + str(t.duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki jakości klasyfikatorów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 121\n",
    "clfs = MinorClassifiers(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = svd_x_train.shape[0]\n",
    "m2 = int(m*0.1)\n",
    "svd_x_train_10 = svd_x_train[:m2]\n",
    "y_train_10 = y_train[:m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1884, 500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_x_train_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_40 = make_noise_label(y_train, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846,)\n",
      "(18846, 500)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_40.shape)\n",
    "print(svd_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\majer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=121).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#UWAGA NIE PUSZCZAĆ BEZ POWODU - linijka niezakomentowana żeby uniknąć restartowania kernela\n",
    "#cross-validation -> wybór metody fuzji decyzji?\n",
    "scores = cross_validate(clfs, svd_x_train, y_train, cv=5, scoring=('accuracy', \n",
    "                                                    'neg_log_loss', \n",
    "                                                    'neg_mean_squared_error', \n",
    "                                                    'roc_auc_ovr', \n",
    "                                                    'f1_weighted', \n",
    "                                                    'precision_weighted', \n",
    "                                                    'recall_weighted'))\n",
    "#print(scores['test_accuracy'])\n",
    "#print(scores['test_neg_log_loss'])\n",
    "#print(scores['test_precision_weighted'])\n",
    "#print(scores['test_recall_weighted'])\n",
    "#print(scores['test_f1_weighted'])\n",
    "#print(scores['test_roc_auc_ovr'])\n",
    "#print(scores['test_average_precision'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([456.73319173, 458.01375389, 459.7722764 , 461.8099308 ,\n",
       "        466.41780066]),\n",
       " 'score_time': array([117.90738559, 119.20071459, 120.67032194, 118.62991047,\n",
       "        119.7404778 ]),\n",
       " 'test_accuracy': array([0.83262599, 0.83709207, 0.83894932, 0.79994694, 0.80100822]),\n",
       " 'test_neg_log_loss': array([-0.87120483, -0.85184481, -0.90018811, -0.87375549, -0.89624805]),\n",
       " 'test_neg_mean_squared_error': array([ -8.53899204,  -8.32342796,  -7.82515256, -11.96975325,\n",
       "        -11.44866012]),\n",
       " 'test_roc_auc_ovr': array([0.98636978, 0.98694682, 0.98709906, 0.98243303, 0.98239627]),\n",
       " 'test_f1_weighted': array([0.83334755, 0.83653121, 0.8395049 , 0.7999577 , 0.80079059]),\n",
       " 'test_precision_weighted': array([0.83628244, 0.8376113 , 0.84178961, 0.80360644, 0.80461577]),\n",
       " 'test_recall_weighted': array([0.83262599, 0.83709207, 0.83894932, 0.79994694, 0.80100822])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.79\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfs.predict(svd_x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score: {0:0.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss score: 0.72\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clfs.predict_proba(svd_x_test)\n",
    "loss = log_loss(y_test, y_pred_proba)\n",
    "print('Loss score: {0:0.2f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-8aaf108fd516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maverage_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision-recall score: {0:0.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_precision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[1;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[0;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[1;32m--> 215\u001b[1;33m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "average_precision = average_precision_score(y_test, y_pred, pos_label=1)\n",
    "print('Precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[2.0,3.0], [2.0,4.], [4.,5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22475435 -0.06248808 -0.01441603 ... -0.0168442   0.02101432\n",
      "  -0.0191214 ]\n",
      " [ 0.12599262 -0.08438557 -0.0357827  ... -0.01513339  0.00517915\n",
      "   0.02194321]\n",
      " [ 0.3346583  -0.04556982 -0.07380376 ...  0.00602186  0.01392154\n",
      "  -0.02985655]\n",
      " ...\n",
      " [ 0.1662913  -0.00550221 -0.0884303  ...  0.01776318 -0.00348805\n",
      "   0.01692393]\n",
      " [ 0.20675388 -0.07267247  0.03741476 ...  0.03050179  0.02278233\n",
      "  -0.02552414]\n",
      " [ 0.09054867 -0.09988643  0.00410151 ...  0.00048173 -0.02367268\n",
      "   0.00355212]]\n"
     ]
    }
   ],
   "source": [
    "c = make_noise_data(svd_x_train, 0.1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
